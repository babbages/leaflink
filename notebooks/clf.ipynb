{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, openai\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "serpapi = \"6b59fda7f62498c8341997204d28288d45372c1eb87650af992693ba0ae59b5d\"\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "os.environ['SERPAPI_API_KEY'] = serpapi\n",
    "search_tool = load_tools(['serpapi'])\n",
    "tools = [search_tool[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "f = open('../secrets.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "\n",
    "API_KEY = data['org-key']# great learning resource wasn't working, so I used my own OpenAI API key\n",
    "OPENAI_API_BASE = \"https://api.openai.com/v1/\"\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = API_KEY\n",
    "os.environ['OPENAI_API_BASE'] = OPENAI_API_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Construct the OpenAI Tools agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"category_number\": 3,\n",
      "  \"category_name\": \"Questions about the plant\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '\\n            You are a master AI that can control other AI agents. You are specifically designed to automate plant maintenance.\\n            You will recieve a prompt from a user, and will have to classify the prompt\\'s purpose as one of the following categories:\\n            [1] Plant Maintenance\\n            [2] AI modeling & EDA\\n            [3] Questions about the plant\\n\\n            Some samples of the prompts are:\\n            [1] \"Release the fertilizer\", \"Turn lights on\", \"Turn lights off\", \"Water the plant\"\\n            [2] \"What is the accuracy of the model?\", \"What is the distribution of the data?\", \"What is the correlation between the features?\", \"Train a regression model\", \"Plot the distribution of the data\"\\n            [3] \"What\\'s the optimum moisture of the plant?\", \"Where does it generally grow?\", \"What is the plant\\'s life cycle?\", \"What is the plant\\'s scientific name?.\\n\\n            Return the category number and name of the prompt in a JSON format.\\n\\n            User: Are you getting enough moisture?\\n',\n",
       " 'output': '{\\n  \"category_number\": 3,\\n  \"category_name\": \"Questions about the plant\"\\n}'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"Are you getting enough moisture?\"\n",
    "\n",
    "full_prompt = f\"\"\"\n",
    "            You are a master AI that can control other AI agents. You are specifically designed to automate plant maintenance.\n",
    "            You will recieve a prompt from a user, and will have to classify the prompt's purpose as one of the following categories:\n",
    "            [1] Plant Maintenance\n",
    "            [2] AI modeling & EDA\n",
    "            [3] Questions about the plant\n",
    "\n",
    "            Some samples of the prompts are:\n",
    "            [1] \"Release the fertilizer\", \"Turn lights on\", \"Turn lights off\", \"Water the plant\"\n",
    "            [2] \"What is the accuracy of the model?\", \"What is the distribution of the data?\", \"What is the correlation between the features?\", \"Train a regression model\", \"Plot the distribution of the data\"\n",
    "            [3] \"What's the optimum moisture of the plant?\", \"Where does it generally grow?\", \"What is the plant's life cycle?\", \"What is the plant's scientific name?.\n",
    "\n",
    "            Return the category number and name of the prompt in a JSON format.\n",
    "\n",
    "            User: {user_prompt}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "agent_executor.invoke({\"input\": full_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
